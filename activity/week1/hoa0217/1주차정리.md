## 성능 테스트
시스템은 부하를 받을 때는 예기치 못한 여러 가지 문제가 발생할 수 있다. 그리고 개발자는 해당 위험에 대비를 해야하기 때문에 일반적으로 시스템에 강제로 부하를 주는 성능 테스트를 수행한다.

이때 효과적인 테스트를 위해서는 하나의 스크립트만 주구장창 수행하는 것으로는 충분하지 않다. 다양한 트래픽 패턴을 고려하여 아래와 같이 여러 유형의 테스트를 수행하는 것이 좋다.

![](https://velog.velcdn.com/images/gjwjdghk123/post/49a08aff-c95c-4058-a85d-885a1eaec478/image.png)

### 스모크 테스트(Smoke tests)
![](https://velog.velcdn.com/images/gjwjdghk123/post/9705ffb2-1bb6-4f14-a334-1e30dc6f8e40/image.png)

- 스크립트가 제대로 작동하는지, 그리고 시스템이 최소 부하에서 제대로 동작하는지 검증한다.
- 기본 성능 메트릭을 수집하기 위해 해당 테스트를 실행하며 소수의 VU(가상 사용자)를 사용하여 테스트를 실행한다.
- 낮은 반복 횟수를 가지고 짧은 지속 시간(몇초 ~ 몇분)으로 수행된다.
- ex) VU(2 ~ 20명), 지속시간(30초 ~ 3분)

> 테스트 스크립트 또는 어플리케이션 코드가 업데이트 될 때마다 스모크 테스트를 수행하는 것을 권장

### 평균 부하 테스트(Average-load test)
![](https://velog.velcdn.com/images/gjwjdghk123/post/5eff8a5f-bbc6-4caa-b4c3-c8506979e0b5/image.png)

- 일반적인 부하(프로덕션 환경에서의 평균적인 상황)에서 시스템이 어떻게 동작하는지 평가한다.
- 평균적인 동시 사용자 수와 RPS를 고려하여 점진적으로 부하를 증가시킨 후 일정시간 동안 유지한다.
- 주기적으로 실행하여 평균 사용량에서 성능을 유지하는지 확인한다.
- 랩프업(부하 증가) + 플래토(유지) + 램프다운(부하감소) 형태로 수행한다.
- 램프업은 전체 테스트 기간 5~15%를 설정한다.

> 평균 처리량 파악을 위해 APM이나 분석도구를 참고하여 지정한다.

### 스트레스 테스트(Stress tests)
![](https://velog.velcdn.com/images/gjwjdghk123/post/69206faf-176b-4e75-b7a0-856a25d7434e/image.png)

- 평균 부하보다 더 높은 부하에서 시스템의 성능 한계를 확인한다.
- 평균 부하 테스트 수행 후 스크립트를 재사용하여 실행한다.
- 더 높은 부하를 고려하여 램프업/플래토/램프다운 시간을 평균 부하 테스트 보다 더 길게 진행한다.

### 소크 테스트(Soak tests)
![](https://velog.velcdn.com/images/gjwjdghk123/post/9030624f-288a-4794-8356-b707ead60a74/image.png)

- 평균 부하 테스트의 변형으로, 장기간(몇 시간~며칠) 동안 시스템의 안정성과 자원 누수를 평가한다.
- 스모크 및 평균 부하 테스트 수행 후 스크립트를 재사용하여 테스트를 실행한다.
- 장시간 동안 부하를 유지하고 램프업/램프다운 시간은 평균 부하 테스트와 동일하게 진행한다. (부하 수준은 동일)

> 시스템 저하를 확인하는 것이 목적이므로 백엔드 자원과 코드 효율성을 모니터링하는 것을 권장

### 스파이크 테스트(Spike tests)
![](https://velog.velcdn.com/images/gjwjdghk123/post/45025dc8-bb43-4b2d-8286-35a3ca60c15e/image.png)

- 갑작스러운 대규모 트래픽 상황에서 시스템의 견딤과 성능을 평가한다.
- 매우 짧거나 아예 없는 램프업/램프다운 시간을 가지며 바로 높은 부하를 주고 짧은 기간을 유지한다.
- 트래픽 급증 이벤트(ex: 콘서트 티켓판매, 제품 출시 등)를 대비하여 여러번 실행한다.

### 브레이크포인트 테스트(Breakpoint tests)
![](https://velog.velcdn.com/images/gjwjdghk123/post/74310df9-543f-498a-9036-85acf36efae5/image.png)

- 점진적으로 부하를 증가시켜 시스템의 한계점을 파악한다.
- 비현실적으로 높은 수치까지 부하를 점진적으로 증가시켜 임계값이 실패하기 시작할 때 중단한다.
- 시스템 부하 증가가 예상되거나 중요한 코드/인프라 변경됐을 때 실행한다.

> 시스템의 한계점 정의는 다를 수 있다.
- 성능 저하: 응답 시간이 증가하고 사용자 경험이 감소
- 문제 발생: 응답 시간이 너무 길어져 사용자 경험이 크게 악화
- 타임아웃: 응답 시간이 너무 길어져 프로세스가 실패
- 오류 발생: 시스템이 HTTP 오류 코드로 응답하기 시작
- 시스템 붕괴: 시스템이 완전히 멈춤

### 정리
| 유형       | VUs(가상유저)/Throughput(처리량) | 지속 시간(Duration) | 실행 시점(When)                                         |
|----------|---------------------------|-----------------|-----------------------------------------------------|
| 스모크      | 낮음                        | 짧음(몇초 또는 몇분)    | 관련 시스템이나 애플리케이션 코드가 변경될 때 실행. 기능 로직, 기본 지표, 편차를 확인. |
| 평균부하     | 평균                        | 중간(5~60분)       | 시스템이 평균적인 사용량에서 성능을 유지하는지 자주 확인할 때 실행.              |
| 스트레스     | 높음(평균 이상)                 | 중간(5~60분)       | 시스템이 평균 이상의 부하를 받을 가능성이 있을 때, 어떻게 관리하는지 확인할 때 실행.   |
| 소크       | 평균                        | 김(n시간)          | 변경 후 시스템이 장시간 지속적 사용에서 어떻게 성능을 유지하는지 확인할 때 실행.      |
| 스파이크     | 매우 높음                     | 짧음(n분)          | 시스템이 기간성 이벤트나 빈번한 트래픽 급증을 대비할 때 실행.                 |
| 브레이크 포인트 | 한계까지 증가                   | 필요한 만큼          | 시스템의 한계를 식별하기 위해 몇 차례 실행.                           |

> 참고: https://grafana.com/docs/k6/latest/testing-guides/test-types/

---

## 성능 지표
성능을 테스트 했으면 이를 평가하는 기준이 필요하다. 아래 지표를 사용하여 시스템의 정상 작동 여부를 판단하고 성능 저하를 유발하는 병목 현상을 찾아낼 수 있다.

### 1. 응답 시간(Response Time)/지연 시간(Latency Time)
![](https://velog.velcdn.com/images/gjwjdghk123/post/caa43507-71cc-488e-a589-1819daad109b/image.png)

요청을 보낸 시점부터 서버가 응답을 보내기 시작하는 시점까지의 시간으로, 사용자가 체감하는 응답 속도를 반영한다.

- 최소 응답 시간: 가장 빠른 응답 시간.
- 최대 응답 시간: 가장 느린 응답 시간.
- 평균 응답 시간: 모든 요청 응답 시간을 총 요청 수로 나눈 값.
  - `평균 응답 시간 = 총 응답 시간 / 요청 수`
- 90번째 백분위: 가장 빠른 90%의 요청에 해당하는 평균 응답 시간.

### 2. 처리량 (Throughput)
시스템이 일정 시간 동안 처리할 수 있는 요청의 양으로, 서버 성능을 평가하는 주요 지표이다.

- TPS (Transactions Per Second): 초당 처리된 트랜잭션 수
  - `TPS = 총 트랜잭션 수 / 총 소요시간`
- RPS (Requests Per Second): 초당 처리된 요청 수
  - `RPS = 총 요청 수 / 총 소요시간`

### 3. 에러율 (Error Rate)
실패한 요청의 비율로, 시스템 안정성과 문제 발생 여부를 파악하는 데 사용된다.
- `(실패한 요청 수 / 총 요청 수) x 100%`

### 4. CPU 사용률 (CPU Utilization)
처리 중에 사용된 CPU 용량의 비율을 측정하여 CPU 효율성을 평가한다. 만약 특정 작업에서 CPU 사용률이 급격하게 높아진다면 성능 저하를 일으킨다. 특히 어플리케이션 연산에 많은 시간을 소비하고 있음을 나타낸다.
- `(1 - (유휴 시간 / 총 시간)) x 100%`

### 5. 메모리 사용률 (Memory Utilization)
총 메모리 중 사용된 메모리의 비율을 나타내어 만약 메모리 사용량이 비정상적으로 높다면 메모리 누수 또는 메모리 부족일 가능성이 높으며 성능과 확장성에 부정적 영향을 준다. 이는 서버의 자원소비가 크다는 것을 나타낸다. 메모리 사용량을 추적할 때는 페이지 폴트 수와 디스크 접근 시간에 주목해야한다.
- `(사용된 메모리 / 총 메모리) x 100%`

### 6. 평균 지연 시간 (Average Latency Time)
시스템이 사용자 요청에 응답하는 데 걸리는 전체 시간을 측정하며, 일반적으로 밀리초(ms) 단위로 표시한다. 이 값은 처리 시간과 네트워크 전송 시간을 포함한다.
- `서버 처리 시간 + 네트워크 지연 시간`

> `평균 응답 시간`과 같은 메트릭이며 관점의 차이로 보인다.

### 7. 네트워크 지연 시간 (Network Latency Time)
네트워크에서의 데이터 전송 시 발생하는 지연 시간으로, '네트워크 딜레이' 또는 '지연'으로 불린다. 네트워크 전송 거리, 대역폭 한계, 네트워크 기술에 따라 영향을 받는다.
- `응답 시간 - 서버 처리 시간`

### 8. 대기 시간(Wait Time)
요청을 서버에 보낸 순간부터 첫 번째 바이트가 수신될 때까지 걸리는 시간으로, 사용자와 시스템의 대기 시간을 모두 포함한다.
- 사용자 관점: 사용자가 요청을 보낸 순간 부터 시스템 응답이 시작할 때까지 기다리는 시간
  - `응답 시간 - 서버 처리 시간`
- 어플리케이션 관점: 서버가 실제 요청 처리 시작 전까지 대기한 시간. 이는 네트워크지연, 자원경쟁, DB성능문제 등이 영향을 준다.
  - `서버 처리 시간 - 큐 대기 시간`

> `사용자 관점의 대기 시간`과 `네트워크 지연 시간`은 같은 메트릭이며 관점의 차이로 보인다.

### 9. 동시 사용자 수(Concurrent Users)
성능 저하나 오류 없이 동시에 시스템에 접속하여 작업을 수행할 수 있는 최대 사용자 수를 의미한다.

- `Active User + Inactive User`
  - Active User: 활성 사용자, 실제 요청을 보내는 사용자
  - Inactive User: 비활성 사용자, 접속은 했지만 대기 상태 사용자
- `요청 수 x 세션 지속 시간 / 총 시간`
  - 1분동안 300개의 요청이 발생했고 요청 평균 세션 지속 시간이 20초라면?
  - 300 * 20 / 60 = 100명


### 10. 트랜잭션 성공/실패율(Transaction Success/Fail)
성공적으로 완료된 트랜잭션과 실패한 트랜잭션의 비율을 나타낸다.
- 성공율: `(성공한 트랜잭션 수 / 총 트랜잭션 수) x 100%`
- 실패율: `(실패한 트랜잭션 수 / 총 트랜잭션 수) x 100%`

> 참고: https://www.blazemeter.com/blog/key-test-metrics-to-track

---
## 참고: 성능을 측정할 땐, 지연시간과 처리량 두가지 모두 측정해야한다.

예상되는 사용자가 몇명이고 사용자들이 발생시키는 api 요청이 몇건일 때 사용자들이 불편함을 느끼지 않으려면 어느정도의 지연시간 미만으로 처리해야할까?

### 예시

초당 3000개의 요청이 들어올 때 99%의 요청이 100ms 미만으로 처리되어야한다.

- 초당 3000개의 요청: 3000tps 처리량
- 100ms미만으로 처리: 100ms 미만 지연시간
- 99%의 요청: 모든 요청에 대한 지연시간을 100ms 미만으로 만드는것은 불가능하다.

> 많은 변수가 있기때문에 SLO는 대부분 99%, 95% 목표를 잡는다. [참고](https://www.ibm.com/kr-ko/topics/service-level-objective)

### 운영체제와 서버자원

- 어플리케이션을 배포해서 실행시키면 운영체제는 프로세스를 생성해서 관리한다.
- 프로세스는 운영체제가 가지고있는 CPU, 메모리, 디스크를 할당받아 작업을 처리한다.
- 백엔드 어플리케이션이라면 api 요청을 받아 처리하는 과정에서 자원을 사용한다.
- 만약 성능테스트 중 서버가 가지고있는 자원 중 사용량이 높은 자원이 있다면, 해당 자원의 사용률을 낮추는 작업을 고려해야한다. ➡️ 병목지점

![](https://velog.velcdn.com/images/gjwjdghk123/post/5507e22d-3a4b-4f80-b56d-d8d04eafecc9/image.png)

> 프로그램을 실행시키면 메모리 위로 올라와서 프로세스가된다. 그리고 CPU는 프로세스가 가진 코드를 실행시킨다. 하지만 컴퓨터가 가지고 있는 RAM은 한정되어 있기에 실행되는 프로세스 수가 많아지면 RAM위에 모든 프로세스를 올릴 수 없다. 만약 올리면 컴퓨터가 다운될 것이다. 이런 문제를 방지하기 위해 물리적인 메모리를 일부를 디스크에 저장했다가 다시 불러오는 페이징 작업을 수행한다. **결론적으로 프로세스가 실행되기 위해서는 CPU, 메모리, 디스크가 서로 상호작용한다.**

### 지연시간과 처리량의 관계

처리량이 증가하면?
- 서버자원(CPU, 메모리, 디스크) 사용량이 증가한다.
- 프로세스/스레드간 자원사용을 위한 대기시간이 길어진다.
- 대기시간이 길어지면 프로세스/스레드가 경쟁적인 상태가되며 처리량이 평소보다 기대 이상으로 낮아진다.
- 자연스레 지연시간이 길어지고 처리되지못한 요청이 쌓이게되며 타임아웃으로 실패하는 요청이 생기게된다.
---
## 성능 병목지점

> 네트워크 대역폭도 해당되나 이는 제외했습니다.

### 데이터베이스

- DB 역시 하나의 어플리케이션이며 OS에 의해 실행되는 프로세스이다.
- CPU, 메모리, 디스크를 이용해서 애플리케이션이 요구하는 데이터 조작/저장/조회 기능을 수행한다.
- DB의 지연시간이 길어지는 상황에 대해서 알아보자.

#### 많은 요청이 들어올 때

![](https://velog.velcdn.com/images/gjwjdghk123/post/544d5d86-4c79-4fc4-85c3-8d3696f94e3a/image.png)
만약 짧은 시간동안 많은 요청이 들어오면 DB의 자원들을 이용해서 요청을 처리해야하기때문에 경쟁적인 상태에 빠질 수 있으며 자연스레 어플리케이션의 지연시간에 영향을 미친다.

#### 많은 데이터 중 필요한 데이터를 찾아야 할 때

![](https://velog.velcdn.com/images/gjwjdghk123/post/175951b2-736b-4554-8116-91acb52c524c/image.png)
많은 데이터가 저장되어있는지도 지연시간에 영향을 미친다. 1억건이 디스크에 저장이 되어있다면, 데이터 중 일부 메모리에 올리고 CPU가 연산을 하면서 조건에 맞는 데이터를 찾아야한다.

> DB에 특화된 성능 튜닝(인덱스 등)을 통해 해결할 수 있음.

#### 한번에 많은 데이터를 응답으로 줘야할 때

![](https://velog.velcdn.com/images/gjwjdghk123/post/4c002879-7302-4b78-8e6c-bb580a147156/image.png)
만약 많은 데이터를 응답으로 줘야한다면? DB서버 자원도 메모리에 데이터를 올리기 위해 많은 비용이 들것이며, 이를 응답으로 서버에게 주기위해 DB와 서버사이 네트워크 대역폭도 많은 차지를 하게된다.

서버입장에서도 받은 데이터를 메모리에 올려서 처리해야하기 때문에 서버에 들어오는 다른 요청들의 성능에도 함께 영향을 준다.

#### 락이 너무 자주 걸리는 경우

> lock: 특정 스레드가 데이터를 제어하고 있으면 다른 스레드의 접근을 막는 메커니즘

DB는 기본적으로 락을 걸어서 Transactional한 처리를 하는데, 락이 걸리는 만큼 대기시간(지연시간)이 발생한다. 따라서 DB 성능개선이 필요하다면 락이 어떻게 걸리고 있는지 파악해야한다.

때로는 락에 의해 데드락이 발생하기도 하며, 데드락이 발생하면 처리되지 못한 요청들이 계속 쌓이고 결국 DB와 서버의 모든 자원을 고갈시켜버리기 때문에 주의해야한다.

실질적으로 서버의 물리적 자원을 많이 소모하지는 않지만 스레드풀이나 커넥션풀처럼 제한적인 숫자만 생성되는 자원이 빠르게 소모된다.

### 스레드풀과 커넥션풀

#### 스레드풀

![](https://velog.velcdn.com/images/gjwjdghk123/post/5ee030d6-9c7a-4545-82de-c39ade80d633/image.png)

애플리케이션 서버가 요청을 받아서 처리하는 자원을 말한다.

- 자바에서 톰캣과 같은 서버를 사용하면 기본적으로 200개의 스레드가 생성되어 요청을 처리하게된다.
- 이 스레드들은 미리 생성되어 요청을 처리한 후 다시 반납하게 되는데, 이 자원을 미리 만들어두고 재사용하는 개념을 Pool이라고 표현한다.

요청이 많이 들어오면 결국 모든 스레드는 사용중인 상태가 된다. 모든 스레드가 사용중인 상태가 되면, 일부 요청은 Queue에 저장되었다 사용가능한 상태가 되면 그 이후에 처리된다. 하지만 Queue 역시 모두 찰 경우 그 이후에 들어오는 요청들은 버려지게된다.

#### 그렇다고 무작정 스레드 숫자를 늘리게 되면 어떻게될까?

동시에 너무 많은 요청을 처리하려고하면 서버의 물리적 자원이 고갈되거나 지나치게 경쟁적인 상태가 될 수 있으며, 오히려 적은 스레드로 요청을 처리하는 것보다 처리량이 낮아질 수 있다. 스레드 숫자를 늘리기보단 로드밸런싱을 통해 여러 서버가 트래픽을 받도록 개선하거나, 비동기적으로 요청을 처리하도록 방식을 바꾸는 방법 등이 있다.

하지만 단순히 위 방법을 도입한다고해서 성능이 개선되지 않을 수 있다.

![](https://velog.velcdn.com/images/gjwjdghk123/post/12ca23f5-752a-4d66-862e-297e1b2e1292/image.png)

만약 어플리케이션 요청을 처리하면서 다른 인프라 요소(DB, 메시지큐, 다른 api 서버 등)에 의존하고 있다면, 그 요소에 많은 부하가 가해질 것이다. 만약 해당 요소가 느려지게 된다면 전체 어플리케이션 성능은 그에 맞춰질 것이고 이때 병목이 발생하게 된다. 이때는 병목되는 부분을 개선하거나 시스템 설계 자체를 구조적으로 바꿔야할 수 있다.

#### 커넥션풀

![](https://velog.velcdn.com/images/gjwjdghk123/post/9b5f6b88-8be9-4b76-ad5d-934352b4d4fe/image.png)

백엔드 어플리케이션과 DB가 서로 데이터를 주고받기 위해 맺는 Pool이다. 스레드풀과 마찬가지로 미리 생성해두고 재사용하게되는데, 처리량이 많아지면 커넥션풀 역시 빠르게 고갈될 수 있다.

만약 어플리케이션 서버를 여러 대 띄우게 된다면 DB와 맺는 커넥션 수는 많아질 것이다. 문제는 DB가 최대 커넥션 수 제한을 걸어놨을 수 있기 때문에, 나중에 뜨는 서버들은 커넥션을 생성하지 못하고 커넥션풀이 정상적으로 생성되지 않을 수 있다. 따라서 꼭 확인을 해봐야한다.

> 스레드풀과 커넥션풀은 여러번 성능테스트를 해보며 적절한 숫자를 찾아 설정해야한다.

> 참고: [백엔드 애플리케이션 성능 테스트하기](https://www.inflearn.com/course/%EB%B0%B1%EC%97%94%EB%93%9C-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EC%84%B1%EB%8A%A5-%ED%85%8C%EC%8A%A4%ED%8A%B8)

---
## 성능테스트 tool

### nGrinder

> 참고: https://naver.github.io/ngrinder/

nGrinder는 네이버에서 개발한 Enterpise 레벨 Java기반 성능 테스트 도구이다. Agent가 반드시 필요하며, Controller는 이를 조종하는 역할을 한다. 분산 테스트/Web UI/Multi Tenancy 지원하고 Groovy/Jyshon으로 테스트 스크립트를 작성할
수 있다. 장점으로는 트랜잭션을 자유롭게 정의할 수 있으며(여러 요청을 하나의 Test로 묶을 수 있음) 스크립트 버전을 관리할 수 있고 실행한 테스트의 결과 또한 자동으로 저장 및 관리할 수 있다.

![](https://velog.velcdn.com/images/gjwjdghk123/post/a1d7f571-d919-4e2c-87cf-012412144691/image.png)

- Controller : 부하테스트를 위한 스크립트 관리 / Agent 제어
- Agent : 스크립트 실행
- Monitor : 타켓 서버의 성능 측정 (거의 사용되지 않음)

### Artillery

> 참고: https://www.artillery.io/

Node.js 기반의 성능 테스트 도구로 HTTP/HTTPS, WebSocket, Socket.io 등 다양한 프로토콜과 애플리케이션에 대한 성능 테스트를 지원한다. npm으로 라이브러리를 설치하여 json 혹은 yaml 파일로 시나리오를 작성해 간단하게 테스트를 진행할 수 있다는
장점이 있다. 하지만 복잡한 테스트가 필요할 경우 제한적일 수 있으며, 여러 테스트 결과를 비교 분석하기에 불편할 수 있다.

![](https://velog.velcdn.com/images/gjwjdghk123/post/e2713c9c-1e13-4619-a444-3f08445af038/image.png)

### K6

> 참고: https://k6.io/docs/

k6는 Grafana에서 만든 성능 테스트 도구로 JavaScript로 스크립트를 작성해 여러 가상 사용자가 애플리케이션에 요청을 보내도록 시뮬레이션하여 부하를 측정할 수 있다. (가상유저, 반복, 서버응답시간, 처리량 등 확인 가능)
Grafana 진영에서 개발했기때문에 Grafana와 연동이 수월하다는 장점을 가지고 있다. 또한 Go언어로 작성되어 가벼운 메모리 사용량과 높은 성능을 가지고 있다.

#### 설치

```
brew install k6
```

#### 스크립트 작성 및 수행

script.js

```
import http from 'k6/http';
import { sleep } from 'k6';

export default function () {
  http.get('https://test.k6.io');
  sleep(1);
}
```

```
k6 run script.js
```

#### 실행결과

![](https://velog.velcdn.com/images/gjwjdghk123/post/b4607136-e8f6-4f77-ad59-bcda73de5fd0/image.png)

> 사용방법 참고: https://devocean.sk.com/blog/techBoardDetail.do?ID=164237
