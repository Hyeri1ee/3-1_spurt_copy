## 성능지표
### 트래픽
트래픽은 특정 기간 동안 서버 또는 네트워크로 들어오는 요청이나 데이터의 양을 말한다. 트래픽이 많아질수록 서버는 더 많은 요청을 처리해야 하므로 서버 성능에 대한 요구가 높아진다.

트래픽은 주로 **초당 요청 수 (RPS)**나 **초당 트랜잭션 수 (TPS)**와 같은 처리량 지표로 측정된다.

높은 트래픽을 처리할 수 있는 시스템은 확장성(Scalability)이 뛰어난 것으로 평가되며, 갑작스럽게 트래픽이 몰려도 안정적으로 작동할 수 있는지 확인하기 위해 성능 테스트를 수행한다.

### 지연시간(Latency)
- 지연 시간은 요청을 보낸 시점부터 서버가 응답을 보내기 시작하는 시점까지 걸리는 시간을 말한다.
- 즉, 한건을 처리하는데 얼마나 걸리는지를 알 수 있으며 사용자가 직접 체감하는 성능이다.
- 낮은 지연시간이 유지될 수록 사용자는 더 빠른 응답을 경험하게된다.

지연시간은 아래와 같은 종류로 나뉠 수 있다.

- 네트워크 지연(Network Latency): 데이터가 네트워크를 통해 전송될 때 발생하는 지연.
- 애플리케이션 지연(Application Latency): 서버 애플리케이션이 요청을 처리하는 데 걸리는 시간.
- 엔드투엔드 지연(End-to-End Latency): 클라이언트가 요청을 보낸 시점부터 응답을 완전히 수신할 때까지의 총 소요 시간.

또한 어떤 서비스냐에따라 사용자가 기대하는 지연시간이 다를 수 있다.
- 인프런 강의 목록 불러오는 경우 ➡️ 1000ms 안쪽
- 항공권 가격 비교 검색의 경우 ➡️ 수초~수십초

### 처리량(Throughput)
시스템이 일정 시간 동안 처리할 수 있는 요청의 양을 의미하며, 서버 성능을 평가하는 주요 지표이다.

TPS (Transactions Per Second)
- TPS는 초당 트랜잭션 수를 의미하며, 특정 시간 동안 시스템이 성공적으로 처리한 트랜잭션의 수를 나타낸다.
- 여기서 트랜잭션은 하나의 완전한 작업 또는 일련의 작업을 의미하며, 예를 들어, 은행 시스템에서 이체 요청이나 결제 승인은 하나의 트랜잭션으로 간주될 수 있다.
- 일반적으로 TPS는 데이터베이스와 같은 트랜잭션 기반 시스템에서 주로 사용되며, 이 값이 높을수록 시스템이 더 많은 작업을 효율적으로 처리할 수 있음을 의미한다.

RPS (Requests Per Second)
- RPS는 초당 요청 수를 의미하며, 웹 애플리케이션이나 API 서버에 초당 얼마나 많은 요청이 들어오는지를 측정한다.
- 이 지표는 서버가 얼마나 많은 HTTP 요청을 처리할 수 있는지를 나타내며, 웹 서비스의 부하를 측정하는 중요한 지표로 사용된다.
- RPS는 일반적으로 웹 서버나 API 서버의 성능을 평가할 때 사용되며, 시스템이 높은 부하를 처리할 수 있는지 확인하는 데 유용하다.

TPS와 RPS의 차이점
- TPS는 주로 데이터베이스나 트랜잭션 기반 시스템에서 사용되는 지표로, 하나의 트랜잭션이 여러 개의 요청으로 구성될 수 있다. ex) 쇼핑몰 결제 요청 시 `장바구니 확인 + 결제 승인 + 재고 업데이트`
- RPS는 개별 요청을 기준으로 측정되며, 주로 웹 애플리케이션의 요청 처리 능력을 평가하는 데 사용된다.

### 성능을 측정할 땐, 지연시간과 처리량 두가지 모두 측정해야한다.
예상되는 사용자가 몇명이고 사용자들이 발생시키는 api 요청이 몇건일 때 사용자들이 불편함을 느끼지 않으려면 어느정도의 지연시간 미만으로 처리해야할까?

#### 예시
초당 3000개의 요청이 들어올 때 99%의 요청이 100ms 미만으로 처리되어야한다.
- 초당 3000개의 요청: 3000tps 처리량
- 100ms미만으로 처리: 100ms 미만 지연시간
- 99%의 요청: 모든 요청에 대한 지연시간을 100ms 미만으로 만드는것은 불가능하다.
    - 성능테스트에는 많은 변수가 있기때문에 대부분 99%, 95% 목표를 잡는다.

> 일반적으로 처리량이 낮으면 지연시간이 낮고 일정하게 유지된다. 하지만 처리량이 점점 늘어나면 서버 자원이 부족해지기 때문에 대기시간이 필요해질 것이고 자연스레 지연시간은 높아지기때문에 지연시간과 처리량을 동시에 목표로 잡아야한다.

### 참고: 운영체제와 서버자원
- 백엔드 어플리케이션을 배포해서 실행시키면 운영체제는 프로세스를 생성해서 관리한다.
- 프로세스는 운영체제가 가지고있는 CPU, 메모리, 디스크를 할당받아 작업을 처리한다.
- 백엔드 어플리케이션이라면 api 요청을 받아 처리하는 과정에서 자원을 사용한다.
- 만약 성능테스트 중 서버가 가지고있는 자원 중 사용량이 높은 자원이 있다면, 해당 자원의 사용률을 낮추는 작업을 고려해야한다. ➡️ 병목지점

![](https://velog.velcdn.com/images/gjwjdghk123/post/5507e22d-3a4b-4f80-b56d-d8d04eafecc9/image.png)

> 프로그램을 실행시키면 메모리 위로 올라와서 프로세스가된다. 그리고 CPU는 프로세스가 가진 코드를 실행시킨다. 하지만 컴퓨터가 가지고 있는 RAM은 정해져있기 때문에 실행되는 프로세스 수가 많아지면 RAM위에 모든 프로세스를 올릴 수 없다. 만약 올리면 컴퓨터가 다운될 것이다. 이런 문제를 방지하기 위해 물리적인 메모리를 일부를 디스크에 저장했다가 다시 불러오는 페이징 작업을 수행한다. 따라서 결론적으로 *프로세스가 실행되기 위해서는 CPU, 메모리, 디스크가 서로 상호작용한다.*

### 지연시간과 처리량의 관계
처리량이 증가하면? 서버자원(CPU, 메모리, 디스크) 사용량이 증가한다. 그리고 프로세스/스레드간 자원사용을 위한 대기시간이 길어진다. 대기시간이 길어지면 프로세스/스레드가 경쟁적인 상태가되며 처리량이 평소보다 기대 이상으로 낮아진다. 자연스레 지연시간이 길어지고 처리되지못한 요청이 쌓이게되며 타임아웃으로 실패하는 요청이 생기게된다.

## 성능 병목지점
> 네트워크 대역폭도 해당되나 이는 제외했습니다.

### 데이터베이스
- DB 역시 하나의 어플리케이션이며 OS에 의해 실행되는 프로세스이다.
- CPU, 메모리, 디스크를 이용해서 애플리케이션이 요구하는 데이터 조작/저장/조회 기능을 수행한다.
- DB의 지연시간이 길어지는 상황에 대해서 알아보자.

#### 많은 요청이 들어올 때
![](https://velog.velcdn.com/images/gjwjdghk123/post/544d5d86-4c79-4fc4-85c3-8d3696f94e3a/image.png)
만약 짧은 시간동안 많은 요청이 들어오면 DB의 자원들을 이용해서 요청을 처리해야하기때문에 경쟁적인 상태에 빠질 수 있으며 자연스레 어플리케이션의 지연시간에 영향을 미친다.

#### 많은 데이터 중 필요한 데이터를 찾아야 할 때
![](https://velog.velcdn.com/images/gjwjdghk123/post/175951b2-736b-4554-8116-91acb52c524c/image.png)
많은 데이터가 저장되어있는지도 지연시간에 영향을 미친다. 1억건이 디스크에 저장이 되어있다면, 데이터 중 일부 메모리에 올리고 CPU가 연산을 하면서 조건에 맞는 데이터를 찾아야한다.

> DB에 특화된 성능 튜닝(인덱스 등)을 통해 해결할 수 있음.

#### 한번에 많은 데이터를 응답으로 줘야할 때
![](https://velog.velcdn.com/images/gjwjdghk123/post/4c002879-7302-4b78-8e6c-bb580a147156/image.png)
만약 많은 데이터를 응답으로 줘야한다면? DB서버 자원도 메모리에 데이터를 올리기 위해 많은 비용이 들것이며, 이를 응답으로 서버에게 주기위해 DB와 서버사이 네트워크 대역폭도 많은 차지를 하게된다. 서버입장에서도 받은 데이터를 메모리에 올려서 처리해야하기 때문에 서버에 들어오는 다른 요청들의 성능에도 함께 영향을 준다.

#### 락이 너무 자주 걸리는 경우
> lock: 특정 스레드가 데이터를 제어하고 있으면 다른 스레드의 접근을 막는 메커니즘

DB는 기본적으로 락을 걸어서 Transactional한 처리를 하는데, 락이 걸리는 만큼 대기시간(지연시간)이 발생한다. 따라서 DB 성능개선이 필요하다면 락이 어떻게 걸리고 있는지 파악해야한다. 때로는 락에 의해 데드락이 발생하기도 하며, 데드락이 발생하면 처리되지 못한 요청들이 계속 쌓이고 결국 DB와 서버의 모든 자원을 고갈시켜버리기 때문에 주의해야한다. 실질적으로 서버의 물리적 자원을 많이 소모하지는 않지만 스레드풀이나 커넥션풀처럼 제한적인 숫자만 생성되는 자원이 빠르게 소모된다.

### 스레드풀과 커넥션풀

#### 스레드풀
![](https://velog.velcdn.com/images/gjwjdghk123/post/5ee030d6-9c7a-4545-82de-c39ade80d633/image.png)

애플리케이션 서버가 요청을 받아서 처리하는 자원을 말한다.
- 자바에서 톰캣과 같은 서버를 사용하면 기본적으로 200개의 스레드가 생성되어 요청을 처리하게된다.
- 이 스레드들은 미리 생성되어 요청을 처리한 후 다시 반납하게 되는데, 이 자원을 미리 만들어두고 재사용하는 개념을 Pool이라고 표현한다.

요청이 많이 들어오면 결국 모든 스레드는 사용중인 상태가 된다. 모든 스레드가 사용중인 상태가 되면, 일부 요청은 Queue에 저장되었다 사용가능한 상태가 되면 그 이후에 처리된다. 하지만 Queue 역시 모두 찰 경우 그 이후에 들어오는 요청들은 버려지게된다.

그렇다고 무작정 스레드 숫자를 늘리게 되면 어떻게될까?

동시에 너무 많은 요청을 처리하려고하면 서버의 물리적 자원이 고갈되거나 지나치게 경쟁적인 상태가 될 수 있으며, 오히려 적은 스레드로 요청을 처리하는 것보다 처리량이 낮아질 수 있다. 스레드 숫자를 늘리기보단 로드밸런싱을 통해 여러 서버가 트래픽을 받도록 개선하거나, 비동기적으로 요청을 처리하도록 방식을 바꾸는 방법 등이 있다.

하지만 단순히 위 방법을 도입한다고해서 성능이 개선되지 않을 수 있다.

![](https://velog.velcdn.com/images/gjwjdghk123/post/12ca23f5-752a-4d66-862e-297e1b2e1292/image.png)

만약 어플리케이션 요청을 처리하면서 다른 인프라 요소(DB, 메시지큐, 다른 api 서버 등)에 의존하고 있다면, 그 요소에 많은 부하가 가해질 것이다. 만약 해당 요소가 느려지게 된다면 전체 어플리케이션 성능은 그에 맞춰질 것이고 이때 병목이 발생하게 된다. 이때는 병목되는 부분을 개선하거나 시스템 설계 자체를 구조적으로 바꿔야할 수 있다.

#### 커넥션풀

![](https://velog.velcdn.com/images/gjwjdghk123/post/9b5f6b88-8be9-4b76-ad5d-934352b4d4fe/image.png)

백엔드 어플리케이션과 DB가 서로 데이터를 주고받기 위해 맺는 Pool이다. 스레드풀과 마찬가지로 미리 생성해두고 재사용하게되는데, 처리량이 많아지면 커넥션풀 역시 빠르게 고갈될 수 있다.

만약 어플리케이션 서버를 여러 대 띄우게 된다면 DB와 맺는 커넥션 수는 많아질 것이다. 문제는 DB가 최대 커넥션 수 제한을 걸어놨을 수 있기 때문에, 나중에 뜨는 서버들은 커넥션을 생성하지 못하고 커넥션풀이 정상적으로 생성되지 않을 수 있다. 따라서 꼭 확인을 해봐야한다.

> 스레드풀과 커넥션풀은 여러번 성능테스트를 해보며 적절한 숫자를 찾아 설정해야한다.

## 성능테스트 tool
### nGrinder
> 참고: https://naver.github.io/ngrinder/

nGrinder는 네이버에서 개발한 Enterpise 레벨 Java기반 성능 테스트 도구이다. Agent가 반드시 필요하며, Controller는 이를 조종하는 역할을 한다. 분산 테스트/Web UI/Multi Tenancy 지원하고 Groovy/Jyshon으로 테스트 스크립트를 작성할 수 있다. 장점으로는 트랜잭션을 자유롭게 정의할 수 있으며(여러 요청을 하나의 Test로 묶을 수 있음) 스크립트 버전을 관리할 수 있고 실행한 테스트의 결과 또한 자동으로 저장 및 관리할 수 있다.

![](https://velog.velcdn.com/images/gjwjdghk123/post/a1d7f571-d919-4e2c-87cf-012412144691/image.png)

- Controller : 부하테스트를 위한 스크립트 관리 / Agent 제어
- Agent : 스크립트 실행
- Monitor : 타켓 서버의 성능 측정 (거의 사용되지 않음)

### Artillery
> 참고: https://www.artillery.io/

Node.js 기반의 성능 테스트 도구로 HTTP/HTTPS, WebSocket, Socket.io 등 다양한 프로토콜과 애플리케이션에 대한 성능 테스트를 지원한다. npm으로 라이브러리를 설치하여 json 혹은 yaml 파일로 시나리오를 작성해 간단하게 테스트를 진행할 수 있다는 장점이 있다. 하지만 복잡한 테스트가 필요할 경우 제한적일 수 있으며, 여러 테스트 결과를 비교 분석하기에 불편할 수 있다.

![](https://velog.velcdn.com/images/gjwjdghk123/post/e2713c9c-1e13-4619-a444-3f08445af038/image.png)


### K6
> 참고: https://k6.io/docs/

k6는 Grafana에서 만든 성능 테스트 도구로 JavaScript로 스크립트를 작성해 여러 가상 사용자가 애플리케이션에 요청을 보내도록 시뮬레이션하여 부하를 측정할 수 있다. (가상유저, 반복, 서버응답시간, 처리량 등 확인 가능)
Grafana 진영에서 개발했기때문에 Grafana와 연동이 수월하다는 장점을 가지고 있다. 또한 Go언어로 작성되어 가벼운 메모리 사용량과 높은 성능을 가지고 있다.


#### 설치

```
brew install k6
```

#### 스크립트 작성 및 수행
script.js
```
import http from 'k6/http';
import { sleep } from 'k6';

export default function () {
  http.get('https://test.k6.io');
  sleep(1);
}
```

```
k6 run script.js
```

#### 실행결과
![](https://velog.velcdn.com/images/gjwjdghk123/post/b4607136-e8f6-4f77-ad59-bcda73de5fd0/image.png)

> 사용방법 참고: https://devocean.sk.com/blog/techBoardDetail.do?ID=164237